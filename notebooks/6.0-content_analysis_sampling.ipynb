{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bertopic import BERTopic\n",
    "\n",
    "from utils.analysis import load_and_prep_data\n",
    "\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & prep data:\n",
    "- `text_embedding_path`: path to new-line JSON file of document emebddings.\n",
    "- `data_path`: path to processed CSV file containing analytic sample.\n",
    "- `sql_path`: path to SQL database to grab additional columns.\n",
    "- `topic_mapper_path`: path to JSON file mapping observation IDs to topic groups.\n",
    "- `score_mapper_path`: path to JSON file mapping observation IDs to updated scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\n",
    "    \"..\",\n",
    "    \"data\",\n",
    "    \"topic_data\",\n",
    "    \"topic_data.csv\"\n",
    ")\n",
    "\n",
    "sql_path = os.path.join(\n",
    "    \"..\", \n",
    "    \"data\", \n",
    "    \"sqlite\", \n",
    "    \"idw_reddit.db\"\n",
    ")\n",
    "\n",
    "topic_mapper_path = os.path.join(\n",
    "    \"..\", \n",
    "    \"data\", \n",
    "    \"topic_data\", \n",
    "    \"labels\", \n",
    "    \"topic_mapper.json\"\n",
    ")\n",
    "\n",
    "score_mapper_path = os.path.join(\n",
    "    \"..\", \n",
    "    \"data\", \n",
    "    \"updated_scores\", \n",
    "    \"score_mapper.json\"\n",
    ")\n",
    "\n",
    "# load & prep data:\n",
    "df = load_and_prep_data(\n",
    "    data=data_path, \n",
    "    sql_db=sql_path, \n",
    "    topic_group_file=topic_mapper_path, \n",
    "    score_file=score_mapper_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load BERtopic model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_MODEL = \"updated_bertopic_model\"\n",
    "NEW_MODEL_PATH = os.path.join(\"..\", \"data\", \"topic_data\", NEW_MODEL)\n",
    "topic_model = BERTopic.load(NEW_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic representations (for mapping words to topic IDs):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_reps = dict(\n",
    "    zip(\n",
    "        topic_model.get_topic_info()[\"Topic\"],\n",
    "        topic_model.get_topic_info()[\"Representation\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "topic_reps = {k:v for k,v in topic_reps.items() if k != -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_topics = [1, 6, 29, 63, 74, 96, 115, 167, 168, 178, 194, 200, 215, 224, 234, 236, 242]\n",
    "{k:\",\".join(v[:7]) for k,v in topic_reps.items() if k in covid_topics}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation Extracts\n",
    "\n",
    "**Covid-19 relevant topics:**\n",
    "\n",
    "`[1, 6, 29, 63, 74, 96, 115, 167, 168, 178, 194, 200, 215, 224, 236, 242]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_topics = [1, 6, 29, 63, 74, 96, 115, 167, 168, 178, 194, 200, 215, 224, 234, 236, 242]\n",
    "covid_df = df.loc[df[\"new_topic\"].isin(covid_topics)]\n",
    "covid_df[\"date\"] = pd.to_datetime(covid_df[\"date\"])\n",
    "covid_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_counts = topic_model.get_topic_info()\n",
    "covid_counts = covid_counts[covid_counts[\"Topic\"].isin(covid_topics)]\n",
    "covid_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = covid_df.groupby(\"month_year\").size().reset_index(name=\"count\")\n",
    "\n",
    "(\n",
    "    alt.Chart(timeline).mark_line().encode(\n",
    "        x=alt.X(\"month_year:N\", title=\"Month-Year\"),\n",
    "        y=alt.Y(\"count:Q\", title=\"Count\"),\n",
    "        tooltip=[\"month_year\", \"count\"]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in covid_topics:\n",
    "    highest, lowest = (\n",
    "        covid_df.loc[covid_df[\"new_topic\"]==topic][\"score\"].max(), \n",
    "        covid_df.loc[covid_df[\"new_topic\"]==topic][\"score\"].min()\n",
    "    )\n",
    "    \n",
    "    n_above = len(\n",
    "        covid_df.loc[\n",
    "            (covid_df[\"new_topic\"]==topic) &\n",
    "            (covid_df[\"score\"] > 1)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    n_below = len(\n",
    "        covid_df.loc[\n",
    "            (covid_df[\"new_topic\"]==topic) &\n",
    "            (covid_df[\"score\"] < 1)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(f\"Topic {topic} :: >1 = {n_above} ({highest}), <1 = {n_below} ({lowest})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to January 2020 and forwards:\n",
    "start_obs = pd.to_datetime(\"2020-01-01\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "covid_df = df.loc[df[\"new_topic\"].isin(covid_topics)].copy()\n",
    "covid_df = covid_df.loc[covid_df[\"date\"] >= start_obs]\n",
    "\n",
    "# only keep documents that are similar to topic vector:\n",
    "covid_df = covid_df.loc[covid_df[\"topic_sim\"] >= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 400 highest & lowest:\n",
    "N = 400\n",
    "highest = covid_df.sort_values(\"score\", ascending=False).head(N)\n",
    "highest[\"sample_source\"] = \"highest\"\n",
    "\n",
    "lowest = covid_df.sort_values(\"score\", ascending=True).head(N)\n",
    "lowest[\"sample_source\"] = \"lowest\"\n",
    "\n",
    "# random sample 200 that are NOT in the existing set:\n",
    "random_n = 200\n",
    "random_state = 42\n",
    "hi_low_ids = highest[\"full_id\"].tolist() + lowest[\"full_id\"].tolist()\n",
    "random_smpl = covid_df.loc[~covid_df[\"full_id\"].isin(hi_low_ids)].sample(n=random_n, random_state=random_state)\n",
    "random_smpl[\"sample_source\"] = \"random\"\n",
    "\n",
    "# concatenate:\n",
    "sample_df = pd.concat([highest, lowest, random_smpl])\n",
    "assert len(sample_df[\"full_id\"].unique() == len(sample_df)), \"Duplicates found!\"\n",
    "assert (N*2 + random_n) == len(sample_df[\"full_id\"].unique()), \"Duplicates found across samples!\"\n",
    "assert sample_df[\"topic_sim\"].min() >= 0.50, \"Similarity error!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get raw texts:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = os.path.join(\n",
    "    \"..\",\n",
    "    \"data\",\n",
    "    \"sqlite\",\n",
    "    \"idw_reddit.db\"\n",
    ")\n",
    "\n",
    "sql_df = pd.DataFrame()\n",
    "\n",
    "conn = sqlite3.connect(db)\n",
    "tables = [\"comments\", \"posts\"]\n",
    "\n",
    "for table in tables:\n",
    "    if table == \"posts\":\n",
    "        temp = pd.read_sql(f\"SELECT full_id, title, selftext FROM {table}\", conn)\n",
    "        temp.fillna(\" \", inplace=True)\n",
    "        temp[\"text\"] = temp[\"title\"] + \" \" + temp[\"selftext\"]\n",
    "        temp = temp[[\"full_id\", \"text\"]]\n",
    "    else:\n",
    "        temp = pd.read_sql(f\"SELECT full_id, body FROM {table}\", conn)\n",
    "        temp.rename(columns={\"body\": \"text\"}, inplace=True)\n",
    "    sql_df = pd.concat([sql_df, temp])\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = sample_df.merge(sql_df, on=\"full_id\", how=\"left\")\n",
    "sample_df[\"url\"] = \"https://reddit.com\" + sample_df[\"permalink\"]\n",
    "sample_df = sample_df[[\"url\", \"sample_source\", \"score\", \"full_id\", \"unique_id\", \"new_topic\", \"topic_sim\", \"score\", \"date\", \"month_year\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = sample_df.groupby(\"month_year\").size().reset_index(name=\"count\")\n",
    "\n",
    "(\n",
    "    alt.Chart(timeline).mark_line().encode(\n",
    "        x=alt.X(\"month_year:N\", title=\"Month-Year\"),\n",
    "        y=alt.Y(\"count:Q\", title=\"Count\"),\n",
    "        tooltip=[\"month_year\", \"count\"]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df[\"date\"] = sample_df[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "output = sample_df.to_dict(\"records\")\n",
    "\n",
    "with open(\"../doccano/datasets/idw_subreddit_covid_topics.jsonl\", \"w\") as f:\n",
    "    for line in tqdm(output):\n",
    "        f.write(json.dumps(line) +\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idw-article",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
