{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac037b-25ed-49f1-ae01-01c7ded4315d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import backoff\n",
    "\n",
    "from bertopic import BERTopic\n",
    "\n",
    "import openai\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5985484-c3a7-44cb-a08a-68775e5933e6",
   "metadata": {},
   "source": [
    "## Load BERTopic Model\n",
    "- `fit_bertopic_model` in the `models` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d820cce-db6e-4789-8b55-a0dd57bef0de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'fit_bertopic_model'\n",
    "topic_model = BERTopic.load(\n",
    "    os.path.join(\n",
    "        '..',\n",
    "        'data',\n",
    "        'models',\n",
    "        model\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae90e1-93e3-4124-a85b-6a6639d00d39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load embeddings:\n",
    "text_embedding_data = os.path.join(\n",
    "    '..',\n",
    "    'data',\n",
    "    'embeddings',\n",
    "    'full_id_to_embeddings.jsonl'\n",
    ")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "read_lines = 0\n",
    "for chunk in tqdm(pd.read_json(text_embedding_data, lines=True, chunksize=5000)):\n",
    "   #print(f'Reading {len(chunk)} lines (total read so far: {read_lines})')\n",
    "        \n",
    "    df = pd.concat([df, chunk])\n",
    "    read_lines += len(chunk)\n",
    "    del chunk\n",
    "    \n",
    "df.sort_values('full_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('full_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_reps = pd.read_csv(\n",
    "    os.path.join(\n",
    "        '..',\n",
    "        'data',\n",
    "        'training',\n",
    "        'text_representations.csv'\n",
    ")\n",
    ")\n",
    "\n",
    "text_reps = dict(zip(text_reps['full_id'], text_reps['text_representation']))\n",
    "\n",
    "assert sorted(text_reps.keys()) == df['full_id'].tolist()\n",
    "\n",
    "df['text_representation'] = df['full_id'].map(text_reps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee4dcb01",
   "metadata": {},
   "source": [
    "## Look at Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85b4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topic_model.topics_\n",
    "noise = sum([1 for i in topics if i == -1])\n",
    "noise_prop = noise / len(topics)\n",
    "print(f'Noise %: {round(noise_prop*100, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4772c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_reps = dict(\n",
    "    zip(\n",
    "        topic_model.get_topic_info()['Topic'],\n",
    "        topic_model.get_topic_info()['Representation']\n",
    "    )\n",
    ")\n",
    "\n",
    "topic_reps = {k: ','.join(v) for k,v in topic_reps.items()}\n",
    "\n",
    "for topic,words in topic_reps.items():\n",
    "    if topic != -1:\n",
    "        print(f'Topic {topic}: {words}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92fbf5ac-df61-42fa-8c35-942bd294e1c1",
   "metadata": {},
   "source": [
    "## Map Topics to Reddit Posts\n",
    "- Pull original topic labels from topic model\n",
    "- Assign to a column in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['og_topic'] = topic_model.topics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85b56f79-a124-49e4-87ed-beb4f21dcaac",
   "metadata": {},
   "source": [
    "## Dealing With Outliers\n",
    "- Create topic vectors.\n",
    "- Assign noise to most similar topic vector.\n",
    "- Assign **any** document that has cosine similarity to its assigned topic's topic vector that is below `0` to noise (`-1`).\n",
    "- For documents that were originally assigned `-1`:\n",
    "  - If their cosine similarity to their most similar topic vector is >= `0.50`, reassign to the topic.\n",
    "  - Else, keep as noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e2136",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = set(topic_model.get_topic_info()['Topic'])\n",
    "topics.remove(-1)\n",
    "\n",
    "topic_vectors = {}\n",
    "for topic in tqdm(topics):\n",
    "    topic_vectors[topic] = np.vstack(df.loc[df['og_topic']==topic]['embeddings']).mean(axis=0).reshape(1,-1)\n",
    "    \n",
    "for topic in tqdm(topics):\n",
    "    idxs = df.loc[df['og_topic']==topic].index\n",
    "    topic_sims = cosine_similarity(\n",
    "        np.vstack(df.loc[idxs]['embeddings']),\n",
    "        topic_vectors[topic]\n",
    "    )\n",
    "    df.loc[idxs, 'topic_sim'] = topic_sims\n",
    "    \n",
    "# get noise most sim topic:\n",
    "df['new_topic'] = df['og_topic']\n",
    "idxs = df.loc[df['og_topic']==-1].index\n",
    "\n",
    "topic_sims = cosine_similarity(\n",
    "    np.vstack(df.loc[idxs]['embeddings']),\n",
    "    np.vstack(list(topic_vectors.values()))\n",
    ")\n",
    "\n",
    "topic_ids = [np.argmax(arr) for arr in topic_sims]\n",
    "cosine_sims = [arr[np.argmax(arr)] for arr in topic_sims]\n",
    "\n",
    "df.loc[idxs, 'new_topic'] = topic_ids\n",
    "df.loc[idxs, 'topic_sim'] = cosine_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b396cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.set_style('whitegrid')\n",
    "plt.title('Distribution of Document Embedding-Topic Vector Cosine Similarities', size=11, weight='bold', fontfamily='Arial', pad=10)\n",
    "flierprops = dict(marker='x', markersize=1, alpha=0.1, markeredgecolor='#1c1c1c')\n",
    "sns.boxplot(data=df, x='topic_sim', flierprops=flierprops, boxprops={\"facecolor\": (.4, .6, .8, .5)})\n",
    "plt.xticks(list(np.arange(-.10,1.0,.05))+[1.0], size=9)\n",
    "plt.xlabel('Cosine Similarity', size=10, fontfamily='Arial', labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846b72ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic_sim'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c34fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any sim below 0, assign as noise:\n",
    "df.loc[df['topic_sim'] < 0, 'new_topic'] = -1\n",
    "\n",
    "# only keep noise reassigned topics above 0.50 similarity:\n",
    "sim_threshold = 0.50\n",
    "df.loc[(df['og_topic'] == -1) & (df['topic_sim'] < 0.50), 'new_topic'] = -1\n",
    "\n",
    "final_noise = sum([1 for i in df['new_topic'].tolist() if i == -1]) / len(df)\n",
    "print(f'Final noise: {round(final_noise * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_topic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_topic'].value_counts(normalize=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "427a7e81-a560-44f8-b7d2-c90fb8f88e80",
   "metadata": {},
   "source": [
    "## Update BERTopic Model\n",
    "- ***WARNING:*** Updating the following attributes **will** lead to an overwriting of their values in the topic model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21c80b88-2db2-433c-932f-bbe5dcf7b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update topic representations with new documents included:\n",
    "new_topics = df['new_topic'].tolist()\n",
    "\n",
    "cv_model = CountVectorizer(\n",
    "    min_df=1,\n",
    "    max_df=0.95,\n",
    "    stop_words=list(stopwords.words('english')),\n",
    "    ngram_range=(1,1)\n",
    ")\n",
    "\n",
    "topic_model.update_topics(\n",
    "    df['text_representation'].tolist(), \n",
    "    vectorizer_model=cv_model,\n",
    "    top_n_words=20,\n",
    "    topics=new_topics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15a4942",
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic,words in dict(zip(topic_model.get_topic_info()['Topic'], topic_model.get_topic_info()['Representation'])).items():\n",
    "    if topic != -1:\n",
    "        print(f'Topic {topic}: {\", \".join(words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_noise = sum([1 for i in new_topics if i == -1]) / len(new_topics)\n",
    "print(f'Final noise proportion: {round(final_noise*100, 4)}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02fb6b50",
   "metadata": {},
   "source": [
    "## Save Updated Model\n",
    "- Save to the `models` directory\n",
    "  - **Name:** `updated_bertopic_model`\n",
    "- Save updated topic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916845b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_MODEL_OUT = 'updated_bertopic_model'\n",
    "NEW_MODEL_OUT_PATH = os.path.join('..', 'data', 'topic_data', NEW_MODEL_OUT)\n",
    "topic_model.save(NEW_MODEL_OUT_PATH, serialization='safetensors', save_ctfidf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save updated data:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['embeddings'], inplace=True)\n",
    "\n",
    "df.set_index('full_id').to_csv(\n",
    "    os.path.join(\n",
    "        '..',\n",
    "        'data',\n",
    "        'topic_data',\n",
    "        'topic_data.csv'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf260782",
   "metadata": {},
   "source": [
    "`---Complete---`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
